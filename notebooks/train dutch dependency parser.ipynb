{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "# UD_Dutch_LassySmall\n",
    "data_dir = '/home/jvdzwaan/data/UD_Dutch-LassySmall/'\n",
    "test = data_dir + 'nl_lassysmall-ud-test.conllu'\n",
    "train = data_dir + 'nl_lassysmall-ud-train.conllu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy uses a different numbering of the depencency arcs than conllx for Dutch. To transform conll x to spacy format, the root word (with head 0) should be the index in the word list. And all other words should be decremented with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentence(data):\n",
    "    words = []\n",
    "    heads = []\n",
    "    deps = []\n",
    "    parts = data.split('\\n')\n",
    "    if parts:\n",
    "        for part in parts:\n",
    "            if not part.startswith('#'):\n",
    "                d = part.split()\n",
    "                if len(d) > 3:\n",
    "                    words.append(d[1])\n",
    "                    heads.append(int(d[6]))\n",
    "                    if d[7] == 'root':\n",
    "                        deps.append('ROOT')\n",
    "                    else:\n",
    "                        deps.append(d[7])\n",
    "    new_heads = []\n",
    "    for indx, h in enumerate(heads):\n",
    "        if h == 0:\n",
    "            new_heads.append(indx)\n",
    "        else:\n",
    "            new_heads.append(h-1)\n",
    "                \n",
    "    return words, new_heads, deps\n",
    "    \n",
    "\n",
    "def read_connl(filepath):\n",
    "    with codecs.open(filepath, encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    sentences = data.split('\\n\\n')\n",
    "    for sentence in sentences:\n",
    "        yield get_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6642\n",
      "([u'Zij', u'behoort', u'tot', u'de', u'socialistische', u'zuil', u'.'], [1, 1, 5, 5, 5, 1, 1], [u'nsubj', 'ROOT', u'case', u'det', u'amod', u'nmod', u'punct'])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "data = []\n",
    "for w, n, l in read_connl(train):\n",
    "    data.append((w, n, l))\n",
    "print len(data)\n",
    "print data[random.randint(0, len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Parijs-Roubaix', u'is', u'een', u'eendaagse', u'wielerwedstrijd', u'die', u'elk', u'voorjaar', u'wordt', u'verreden', u'in', u'het', u'noorden', u'van', u'Frankrijk', u'.']\n",
      "[4, 4, 4, 4, 4, 9, 7, 9, 9, 4, 12, 12, 9, 14, 12, 4]\n",
      "[u'nsubj', u'cop', u'det', u'amod', 'ROOT', u'nsubj', u'det', u'nmod', u'auxpass', u'acl', u'case', u'det', u'nmod', u'case', u'nmod', u'punct']\n",
      "True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find a gold-standard action to supervise the dependency parser.\nThe GoldParse was projective.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a4b57006b40d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#print sorted(left_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#print sorted(right_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-a4b57006b40d>\u001b[0m in \u001b[0;36mtrain_parser\u001b[0;34m(nlp, train_data, left_labels, right_labels)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#print gold.orig_annot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_projective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvdzwaan/code/spaCy/spacy/syntax/parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.parser.Parser.update (spacy/syntax/parser.cpp:7910)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_featuresC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_costs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_scoresC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnr_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvdzwaan/code/spaCy/spacy/syntax/arc_eager.pyx\u001b[0m in \u001b[0;36mspacy.syntax.arc_eager.ArcEager.set_costs (spacy/syntax/arc_eager.cpp:8530)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \"to the GoldParse class, or use PseudoProjectivity.preprocess_training_data\")\n\u001b[1;32m    458\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find a gold-standard action to supervise the dependency parser.\nThe GoldParse was projective."
     ]
    }
   ],
   "source": [
    "# source: examples/training/train_parser.py\n",
    "import random\n",
    "\n",
    "import spacy\n",
    "from spacy.pipeline import DependencyParser\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def train_parser(nlp, train_data, left_labels, right_labels):\n",
    "    labels = set(left_labels+right_labels)\n",
    "    parser = DependencyParser(\n",
    "                nlp.vocab,\n",
    "                labels=labels)\n",
    "    for itn in range(1000):\n",
    "        random.shuffle(train_data)\n",
    "        loss = 0\n",
    "        for words, heads, deps in train_data:\n",
    "            print words\n",
    "            print heads\n",
    "            print deps\n",
    "            doc = Doc(nlp.vocab, words=words)\n",
    "            gold = GoldParse(doc, heads=heads, deps=deps)\n",
    "            #print gold.cand_to_gold\n",
    "            #print gold.gold_to_cand\n",
    "            #print gold.orig_annot\n",
    "            print gold.is_projective\n",
    "            loss += parser.update(doc, gold)\n",
    "    parser.model.end_training()\n",
    "    return parser\n",
    "\n",
    "nlp = spacy.load('nl', tagger=False, parser=False, entity=False, add_vectors=False)\n",
    "\n",
    "left_labels = set()\n",
    "right_labels = set()\n",
    "for _, heads, deps in data:\n",
    "    for i, (head, dep) in enumerate(zip(heads, deps)):\n",
    "        if i < head:\n",
    "            left_labels.add(dep)\n",
    "        elif i > head:\n",
    "            right_labels.add(dep)\n",
    "#print sorted(left_labels)\n",
    "#print sorted(right_labels)\n",
    "parser = train_parser(nlp, data, sorted(left_labels), sorted(right_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.vocab import Vocab\n",
    "from spacy.pipeline import DependencyParser\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "vocab = Vocab()\n",
    "parser = DependencyParser(vocab, labels=['nsubj', 'compound', 'dobj', 'punct'])\n",
    "\n",
    "doc = Doc(vocab, words=[u'Who', u'is', u'Shaka', u'Khan', u'?'])\n",
    "parser.update(doc, [(1, 'nsubj'), (1, 'ROOT'), (3, 'compound'), (1, 'dobj'),\n",
    "                    (1, 'punct')])\n",
    "\n",
    "parser.model.end_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy uses a different numbering of the depencency arcs than conllx for Dutch. To transform conll x to spacy format, the root word (with head 0) should be the index in the word list. And all other words should be decremented with 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
